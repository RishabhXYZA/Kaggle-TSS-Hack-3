{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8sGFFsOv/iHHVXIhSZwcK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishabhXYZA/Kaggle-TSS-Hack-3/blob/main/Thapar_Summer_School_Kaggle_hack_iii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TSS Hack-3 Kaggle**\n",
        "**(Evaluation done on RMAE)**"
      ],
      "metadata": {
        "id": "BAWrrTI8Dqls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Linear Regression**"
      ],
      "metadata": {
        "id": "DheQqZczDlxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bcOwcVD5Cud",
        "outputId": "f88a7f34-4f15-4433-c68b-dba23162e922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.9114\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "\n",
        "# Optional: split into train/val to evaluate R² properly\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Decision Tree Regressor**"
      ],
      "metadata": {
        "id": "_R3KnOReDzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "\n",
        "# Split data for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "# Compute R² score\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Prepare test features and make predictions\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMmyx3386boC",
        "outputId": "21855f21-8fb3-4ac1-93e0-8c7a7cd8572f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.8517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using AdaBoost and Decision Tree Regressor**"
      ],
      "metadata": {
        "id": "0Jop7MwRD6HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare training features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize AdaBoost Regressor with Decision Tree as base estimator\n",
        "base_estimator = DecisionTreeRegressor(max_depth=5)\n",
        "model = AdaBoostRegressor(estimator=base_estimator, n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdzkVqqs7AvW",
        "outputId": "c45fb4ee-1cf1-42e9-9842-f41ec3c57c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.8860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Decision Tree with PCA and Outlier Removal**"
      ],
      "metadata": {
        "id": "cDYA8oUpEBiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Feature Scaling (required before PCA)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=10)  # You can change n_components as needed\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "\n",
        "test_predictions = model.predict(X_test_pca)\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVeTRslV7s83",
        "outputId": "68f95473-1d28-4042-f4a4-9de90f131dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.8024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Lasso Regressor**"
      ],
      "metadata": {
        "id": "f7Op1AQxEKaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Scale features (important for Lasso)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Lasso Regression model\n",
        "model = Lasso(alpha=0.1, random_state=42)  # You can tune alpha\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j22e0aZR8P1k",
        "outputId": "51a72a1a-97cc-40d8-ba10-7111399683be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.076e+07, tolerance: 1.276e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using KNN (K-Neighbours) Model**"
      ],
      "metadata": {
        "id": "HILdRyhRENhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Feature scaling (very important for KNN)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train KNN Regressor\n",
        "model = KNeighborsRegressor(n_neighbors=5)  # You can tune n_neighbors\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"Rishabh_Bhasin_7009.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWxQ6Ipe8wcG",
        "outputId": "6064249c-fea8-438f-b55e-c1f009190f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.8790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Bayesian Ridge**"
      ],
      "metadata": {
        "id": "JwVE-hLJEUj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Bayesian Ridge Regression model\n",
        "model = BayesianRidge()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"Rishabh_Bhasin_7009_(1).csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOsjpw0-9MTL",
        "outputId": "4cb4991e-a3bd-4ca4-d380-4fc79eaedbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.9115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Random Forest Regressor**"
      ],
      "metadata": {
        "id": "Fa4NejD_EYfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Scale features (optional for Random Forest, but helps for comparison)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set and compute R² score\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qlcxHGT9sEF",
        "outputId": "a4d3fd3d-6032-4525-c11d-ed206f79cbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.9248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Random Forest Regressor with Outlier Removal**"
      ],
      "metadata": {
        "id": "jcd6ckLBEerE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal (optional - basic z-score logic)\n",
        "from scipy.stats import zscore\n",
        "X_numeric = X.select_dtypes(include='number')\n",
        "z_scores = zscore(X_numeric)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor with tuned parameters\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validation R² score\n",
        "val_predictions = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_predictions)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_predictions\n",
        "})\n",
        "submission.to_csv(\"Rishabh_Bhasin_7009_(2).csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bq-iO2X-e7l",
        "outputId": "804b465e-f41c-4a4f-cec4-7704c9bb8a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score on validation set: 0.9186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using RF with Hypertuned model**"
      ],
      "metadata": {
        "id": "nQ0PWDMYEkUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Drop unneeded columns\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Remove outliers using z-score\n",
        "z_scores = zscore(X.select_dtypes(include='number'))\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature Selection (keep only top 20 most relevant)\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Optimized Random Forest Regressor\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=3,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission_path = \"submission_optimized_rf.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsDLZq1v_45Z",
        "outputId": "4f86b533-3d55-499e-f615-4370674a5b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LGBM Regressor**"
      ],
      "metadata": {
        "id": "xICzRVArEr3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Feature/Target separation\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal (z-score method)\n",
        "z_scores = zscore(X.select_dtypes(include='number'))\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection (top 20 best)\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train LGBM model\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate R²\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_lgbm.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FFXaaAMB8Sf",
        "outputId": "310c9510-9763-441f-b4cb-ce53364e3586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 833\n",
            "[LightGBM] [Info] Number of data points in the train set: 7576, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 6013.503117\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "R² Score on validation set: 0.9214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LGBM with Outlier Removal**"
      ],
      "metadata": {
        "id": "0vF6P10-E11Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Split features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Remove outliers using Z-score method\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection - keep top 20 features\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train LGBM Regressor\n",
        "model = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate and evaluate\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_lgbm_outlier.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXwbAAtvCjwv",
        "outputId": "0392e715-fa6a-4821-f3da-b7b8eeb8f6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 833\n",
            "[LightGBM] [Info] Number of data points in the train set: 7576, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 6013.503117\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using MLP Regressor**"
      ],
      "metadata": {
        "id": "-aKw_vw4E74_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Remove outliers using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection (top 20)\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train MLPRegressor (Neural Network)\n",
        "model = MLPRegressor(hidden_layer_sizes=(128, 64, 32),\n",
        "                     activation='relu',\n",
        "                     solver='adam',\n",
        "                     max_iter=1000,\n",
        "                     random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_mlp.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpO0W65qDBs1",
        "outputId": "7037cda7-3696-479f-820c-b5d90333616d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGB Regressor**"
      ],
      "metadata": {
        "id": "42ip1iHZFCxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare inputs\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal (Z-score method)\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Select top 20 features\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train XGBoost Regressor\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate performance\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_xgb.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOJzLcXBDsPh",
        "outputId": "5ed301fc-b215-468f-b397-b9652e0279dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Symbolic Regression**"
      ],
      "metadata": {
        "id": "XeU2MOOXFJ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gplearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMD4MgkWESBW",
        "outputId": "a6ea652d-3113-4d81-b60d-100a3be269c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train Symbolic Regressor\n",
        "model = SymbolicRegressor(\n",
        "    population_size=1000,\n",
        "    generations=30,\n",
        "    tournament_size=20,\n",
        "    stopping_criteria=0.001,\n",
        "    const_range=(-5, 5),\n",
        "    init_depth=(2, 6),\n",
        "    p_crossover=0.7,\n",
        "    p_subtree_mutation=0.1,\n",
        "    p_hoist_mutation=0.05,\n",
        "    p_point_mutation=0.1,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validation performance\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ Symbolic Regression R² on validation: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Submission CSV\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_symbolic_regression.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSm83Q0iEV2y",
        "outputId": "aab6b6be-93a0-4a9b-b413-4c7d0df5f154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0    23.47          10988.1       63          5842.74              N/A      2.46m\n",
            "   1    33.75           6010.6        9          4296.53              N/A      1.47m\n",
            "   2    58.95          6473.74        9          4296.53              N/A      1.54m\n",
            "   3    45.50          25118.2        9           4062.4              N/A      2.24m\n",
            "   4    24.67          89612.3       17          3935.82              N/A      1.21m\n",
            "   5    15.78           177245       15          3712.88              N/A      1.26m\n",
            "   6    19.85           118722       11          3465.58              N/A      1.02m\n",
            "   7    15.31           179116       11          3465.58              N/A      1.50m\n",
            "   8    16.87           170487       17          3322.72              N/A     58.86s\n",
            "   9    14.80           201158       87          3022.58              N/A     49.64s\n",
            "  10    16.55           262698       73          3014.72              N/A     38.35s\n",
            "  11    39.82           157384       85           2986.1              N/A     54.74s\n",
            "  12    80.04          64857.2       93          2974.22              N/A      1.60m\n",
            "  13    83.05          62349.1      109          2961.71              N/A     36.24s\n",
            "  14    92.66          27300.1      109          2839.85              N/A     36.63s\n",
            "  15   103.42          28633.7      109          2788.15              N/A     36.96s\n",
            "  16   110.38            24372      133          2341.38              N/A     46.13s\n",
            "  17   117.39          40043.2      169          2218.02              N/A     36.36s\n",
            "  18   126.56          46955.6      147          1963.86              N/A     31.22s\n",
            "  19   140.85          42075.6      229          1792.18              N/A     32.11s\n",
            "  20   170.79          30526.8      189           1641.8              N/A     40.73s\n",
            "  21   181.31          25910.6      283           1527.5              N/A     29.75s\n",
            "  22   210.19           282876      309          1435.47              N/A     27.45s\n",
            "  23   222.96      1.94743e+06      299          1318.41              N/A     28.81s\n",
            "  24   269.32           311619      307          1242.92              N/A     25.94s\n",
            "  25   287.54      1.26997e+06      269          1127.08              N/A     20.05s\n",
            "  26   289.85          46708.3      271          1126.41              N/A     18.95s\n",
            "  27   286.56          40732.7      271          1053.52              N/A      9.91s\n",
            "  28   274.13          75590.1      275          1007.35              N/A      5.63s\n",
            "  29   272.34          55787.5      273          994.206              N/A      0.00s\n",
            "✅ Symbolic Regression R² on validation: 0.1407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Gradient Boost Regressor**"
      ],
      "metadata": {
        "id": "mcT-yp_2FOt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Split features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using Z-score method\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Feature selection (top 20 features)\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_selected)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_gbr.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21oZlLDzE2z7",
        "outputId": "b641e2d3-ac71-4096-c70b-031f42364cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=20 is greater than n_features=16. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using GBR with PCA and Outlier removal**"
      ],
      "metadata": {
        "id": "BfnhVyC1FTyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCA for dimensionality reduction (keep 95% variance)\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_pca)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_gbr_pca_outliers.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv6Y2lROE3E9",
        "outputId": "9e802db9-8350-46a9-f80e-f53d5501b02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.8898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using GBR with Outlier removal**"
      ],
      "metadata": {
        "id": "JPhaVfA9Fapx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validation predictions and R² score\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_gbr_outliers.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrgLmmJgF2_R",
        "outputId": "e24270ef-5a3e-44f6-fe78-2f6c4eb44b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Passive Agressive Regression Model**"
      ],
      "metadata": {
        "id": "1RfyWLT1FhJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import PassiveAggressiveRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Remove outliers using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train Passive Aggressive Regressor\n",
        "model = PassiveAggressiveRegressor(\n",
        "    max_iter=1000,\n",
        "    tol=1e-3,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate model\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_passive_aggressive.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cL2CZ5UGJDc",
        "outputId": "f68855c5-2127-41bf-b2bf-4d1f1400e99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGB hypertuned model**"
      ],
      "metadata": {
        "id": "qshCM_rRFl0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='r2',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = best_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(\"✅ Best Params:\", grid_search.best_params_)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_xgb_hypertuned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUpu4HltG5-8",
        "outputId": "296262c6-4656-48b3-c6be-77e8db7960e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
            "✅ Best Params: {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.8}\n",
            "✅ R² Score on validation set: 0.9240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGB with learning curve**"
      ],
      "metadata": {
        "id": "_CC_I8P2Fs6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Feature-target split\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize XGBoost model\n",
        "model = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Plot learning curve\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    estimator=model,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    cv=3,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "val_scores_mean = np.mean(val_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', label=\"Training R²\", color='blue')\n",
        "plt.plot(train_sizes, val_scores_mean, 'o-', label=\"Validation R²\", color='orange')\n",
        "plt.title(\"Learning Curve - XGBoost Regressor\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"R² Score\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Train final model on full training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_xgb_learning_curve.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "8scmY-VlH3GC",
        "outputId": "04c0dac7-2729-4de0-a69a-8768ebca5e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Linear Regression with Polynomial Feature**"
      ],
      "metadata": {
        "id": "CcOJ14woFxpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Generate polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X_scaled)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_poly, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Fit linear regression on polynomial features\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_poly)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_polynomial.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhDUFbXZIWa3",
        "outputId": "3088e117-44fa-4f1a-ac5e-f213ee0e9b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.8915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGB with PEP(Prediction Error Plot)**"
      ],
      "metadata": {
        "id": "j-pLqGtxF3Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Train XGBoost Regressor\n",
        "model = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# 📉 Prediction Error Plot (Actual vs Predicted)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_val, val_preds, alpha=0.6, color='blue')\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "plt.xlabel(\"Actual Output\")\n",
        "plt.ylabel(\"Predicted Output\")\n",
        "plt.title(\"Prediction Error Plot (XGBoost)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_xgb_prediction_error_plot.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "0ajsRo4qIYqy",
        "outputId": "a7ba2820-c37f-4463-97f0-f09ce6d1ae52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9216\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Extra Tress Regressor**"
      ],
      "metadata": {
        "id": "7iBPU221F-uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train Extra Trees Regressor\n",
        "model = ExtraTreesRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_extra_trees.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwr8M6ylIY3g",
        "outputId": "b52fc929-a311-4b56-c786-42b179be859d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra Trees with Outlier Removal**"
      ],
      "metadata": {
        "id": "k4p2MH3nGDjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Initialize and train Extra Trees Regressor\n",
        "model = ExtraTreesRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate on validation set\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# ✅ Predict on test data\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_extra_trees_outliers.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFSlTE20JsRc",
        "outputId": "519ab425-b417-4d2a-fec9-3f6fe1ab2dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.9151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Huber Regressor**"
      ],
      "metadata": {
        "id": "n5wwHBk0GIVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Initialize and train Huber Regressor\n",
        "model = HuberRegressor(\n",
        "    epsilon=1.35,  # default is 1.35; tune this if needed\n",
        "    max_iter=1000,\n",
        "    alpha=0.0001\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate model\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation set: {r2:.4f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_huber.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX09Z5mOKJsW",
        "outputId": "638f3986-875c-40f4-f1d2-3497ab12ec25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation set: 0.8816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Catboost Regressor**"
      ],
      "metadata": {
        "id": "dDwMg1lzGLkM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cb5d5b8",
        "outputId": "3f554700-ea5d-4cc2-cc1e-0784001ad237"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Split features/target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal using IQR\n",
        "Q1 = X.quantile(0.25)\n",
        "Q3 = X.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "mask = ~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# First CatBoost run for feature selection\n",
        "selector_model = CatBoostRegressor(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    silent=True,\n",
        "    random_state=42\n",
        ")\n",
        "selector_model.fit(X_train, y_train)\n",
        "selector = SelectFromModel(selector_model, threshold=\"median\", prefit=True)\n",
        "\n",
        "# Reduce features\n",
        "X_train_sel = selector.transform(X_train)\n",
        "X_val_sel = selector.transform(X_val)\n",
        "X_test_sel = selector.transform(X_test_scaled)\n",
        "\n",
        "# Final CatBoost model\n",
        "final_model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.03,\n",
        "    depth=8,\n",
        "    loss_function='RMSE',\n",
        "    early_stopping_rounds=50,\n",
        "    random_state=42,\n",
        "    verbose=100\n",
        ")\n",
        "final_model.fit(X_train_sel, y_train, eval_set=(X_val_sel, y_val))\n",
        "\n",
        "# Evaluate\n",
        "val_preds = final_model.predict(X_val_sel)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² on validation: {r2:.5f}\")\n",
        "\n",
        "# Predict on test\n",
        "test_preds = final_model.predict(X_test_sel)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_catboost_fresh.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG6mhmjzLvfp",
        "outputId": "93ab5ac7-def4-49ad-b98a-52c0e1e6cbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1249.7160923\ttest: 1245.4690240\tbest: 1245.4690240 (0)\ttotal: 5.79ms\tremaining: 5.78s\n",
            "100:\tlearn: 363.5113961\ttest: 396.4623385\tbest: 396.4623385 (100)\ttotal: 409ms\tremaining: 3.64s\n",
            "200:\tlearn: 343.0522191\ttest: 387.2352788\tbest: 387.2235921 (199)\ttotal: 832ms\tremaining: 3.31s\n",
            "300:\tlearn: 333.8870758\ttest: 386.2680490\tbest: 386.2328205 (280)\ttotal: 1.25s\tremaining: 2.9s\n",
            "Stopped by overfitting detector  (50 iterations wait)\n",
            "\n",
            "bestTest = 385.946291\n",
            "bestIteration = 347\n",
            "\n",
            "Shrink model to first 348 iterations.\n",
            "✅ R² on validation: 0.90867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Catboost Tuned  Model**"
      ],
      "metadata": {
        "id": "W3FJL5vUGVv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Focused Hypertuned CatBoost\n",
        "model = CatBoostRegressor(\n",
        "    iterations=1200,\n",
        "    learning_rate=0.025,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=3,\n",
        "    bagging_temperature=0.4,\n",
        "    subsample=0.85,\n",
        "    colsample_bylevel=0.9,\n",
        "    early_stopping_rounds=50,\n",
        "    loss_function='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
        "\n",
        "# R² score on validation\n",
        "val_preds = model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation: {r2:.5f}\")\n",
        "\n",
        "# Predict on test set\n",
        "test_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_catboost_tuned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ns8-oRbPfS1",
        "outputId": "220f4e8e-c268-42cd-bf83-3b5b7253dc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1285.5245514\ttest: 1312.9553503\tbest: 1312.9553503 (0)\ttotal: 16.7ms\tremaining: 20s\n",
            "100:\tlearn: 394.6695604\ttest: 401.6203454\tbest: 401.6203454 (100)\ttotal: 2.11s\tremaining: 23s\n",
            "200:\tlearn: 363.3300555\ttest: 377.1598610\tbest: 377.1322368 (199)\ttotal: 4s\tremaining: 19.9s\n",
            "300:\tlearn: 354.4703916\ttest: 375.3110427\tbest: 375.2186912 (290)\ttotal: 5.2s\tremaining: 15.5s\n",
            "400:\tlearn: 345.7002148\ttest: 374.2282875\tbest: 374.2214609 (398)\ttotal: 6.51s\tremaining: 13s\n",
            "500:\tlearn: 338.2886622\ttest: 373.7903526\tbest: 373.7098923 (465)\ttotal: 7.68s\tremaining: 10.7s\n",
            "Stopped by overfitting detector  (50 iterations wait)\n",
            "\n",
            "bestTest = 373.7098923\n",
            "bestIteration = 465\n",
            "\n",
            "Shrink model to first 466 iterations.\n",
            "✅ R² Score on validation: 0.92225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Stacked XGB with Catboost Regressor**"
      ],
      "metadata": {
        "id": "KCvXJ0r_GcAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Split features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (abs(z_scores) < 3).all(axis=1)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# ✅ Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Base Model 1: Tuned XGBoost\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_val_preds = xgb_model.predict(X_val)\n",
        "xgb_test_preds = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Base Model 2: Tuned CatBoost\n",
        "cat_model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.025,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=3,\n",
        "    bagging_temperature=0.4,\n",
        "    subsample=0.85,\n",
        "    colsample_bylevel=0.9,\n",
        "    early_stopping_rounds=50,\n",
        "    loss_function='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
        "cat_val_preds = cat_model.predict(X_val)\n",
        "cat_test_preds = cat_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Stacking: Combine predictions from both models\n",
        "stacked_val = pd.DataFrame({\n",
        "    'xgb': xgb_val_preds,\n",
        "    'cat': cat_val_preds\n",
        "})\n",
        "stacked_test = pd.DataFrame({\n",
        "    'xgb': xgb_test_preds,\n",
        "    'cat': cat_test_preds\n",
        "})\n",
        "\n",
        "# ✅ Meta-model: Linear Regression\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(stacked_val, y_val)\n",
        "\n",
        "# ✅ Final validation prediction and R² score\n",
        "final_val_preds = meta_model.predict(stacked_val)\n",
        "r2 = r2_score(y_val, final_val_preds)\n",
        "print(f\"✅ R² Score (Stacked) on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Final test prediction\n",
        "final_test_preds = meta_model.predict(stacked_test)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': final_test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_stacked_xgb_cat.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9MQCoAlw-Lm",
        "outputId": "2f872ef5-229c-4047-aae1-c4d059a3add9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score (Stacked) on validation: 0.92346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Polynomial Features**"
      ],
      "metadata": {
        "id": "DBl9j7eFGkFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore, skew\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare data\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Log-transform skewed features\n",
        "for col in X.columns:\n",
        "    if skew(X[col]) > 1:\n",
        "        X[col] = np.log1p(X[col])\n",
        "        X_test[col] = np.log1p(X_test[col])\n",
        "\n",
        "# ✅ Polynomial interactions (degree=2, no bias term)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# ✅ Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_poly)\n",
        "X_test_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ XGBoost Regressor\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=800,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_val_preds = xgb_model.predict(X_val)\n",
        "xgb_test_preds = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ CatBoost Regressor\n",
        "cat_model = CatBoostRegressor(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.025,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=3,\n",
        "    bagging_temperature=0.4,\n",
        "    subsample=0.85,\n",
        "    colsample_bylevel=0.9,\n",
        "    early_stopping_rounds=50,\n",
        "    loss_function='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
        "cat_val_preds = cat_model.predict(X_val)\n",
        "cat_test_preds = cat_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Blending Predictions (Weighted Average)\n",
        "final_val_preds = 0.5 * xgb_val_preds + 0.5 * cat_val_preds\n",
        "final_test_preds = 0.5 * xgb_test_preds + 0.5 * cat_test_preds\n",
        "\n",
        "# ✅ Validation R²\n",
        "r2 = r2_score(y_val, final_val_preds)\n",
        "print(f\"✅ R² Score (Blended) on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': final_test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_blended_engineered.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXG4K-gT1NCC",
        "outputId": "e7006971-cc92-46e3-a3f5-92aa874ea697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score (Blended) on validation: 0.92209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGB with optuna**"
      ],
      "metadata": {
        "id": "t5_wbGJlGr5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xJJWTP32SOg",
        "outputId": "3356e196-5323-4e56-ccdc-9dae0a044065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "from xgboost import XGBRegressor\n",
        "import optuna\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Z-score outlier removal\n",
        "z_scores = np.abs((X - X.mean()) / X.std())\n",
        "X = X[(z_scores < 3).all(axis=1)]\n",
        "y = y[X.index]\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-val split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Optuna objective\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1),\n",
        "        \"random_state\": 42,\n",
        "        \"verbosity\": 0\n",
        "    }\n",
        "    model = XGBRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    return r2_score(y_val, preds)\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=40)\n",
        "\n",
        "# Final model\n",
        "best_params = study.best_params\n",
        "print(\"Best Params:\", best_params)\n",
        "print(\"Best Validation R² Score:\", study.best_value)\n",
        "\n",
        "# Train best model and save predictions\n",
        "best_model = XGBRegressor(**best_params)\n",
        "best_model.fit(X_scaled, y)\n",
        "test_preds = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Submission\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"output\": test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_xgb_optuna.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5dKF3I2S7J",
        "outputId": "c314b787-a9ff-4e77-da67-75e5e8d96bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-08 16:23:46,588] A new study created in memory with name: no-name-b3908d88-8a1b-4e59-aa57-2330c856392a\n",
            "[I 2025-07-08 16:23:49,068] Trial 0 finished with value: 0.9177750916454985 and parameters: {'n_estimators': 631, 'max_depth': 8, 'learning_rate': 0.04620700570890919, 'subsample': 0.9211970260205411, 'colsample_bytree': 0.8211908150733775, 'min_child_weight': 4, 'gamma': 4.86143052933614, 'reg_alpha': 0.06529388205012054, 'reg_lambda': 0.8146253860648923}. Best is trial 0 with value: 0.9177750916454985.\n",
            "[I 2025-07-08 16:24:19,225] Trial 1 finished with value: 0.9129336443805445 and parameters: {'n_estimators': 391, 'max_depth': 10, 'learning_rate': 0.08121667047250489, 'subsample': 0.9044389054002486, 'colsample_bytree': 0.7194219359388657, 'min_child_weight': 3, 'gamma': 0.07204193657737556, 'reg_alpha': 0.8791793911964391, 'reg_lambda': 0.6537632153595268}. Best is trial 0 with value: 0.9177750916454985.\n",
            "[I 2025-07-08 16:24:42,397] Trial 2 finished with value: 0.9192840310934351 and parameters: {'n_estimators': 841, 'max_depth': 7, 'learning_rate': 0.032348872931520806, 'subsample': 0.9941414391023982, 'colsample_bytree': 0.8482817591028304, 'min_child_weight': 1, 'gamma': 2.137495261344118, 'reg_alpha': 0.43360459562787035, 'reg_lambda': 0.7567394491843937}. Best is trial 2 with value: 0.9192840310934351.\n",
            "[I 2025-07-08 16:24:47,511] Trial 3 finished with value: 0.9230744027027956 and parameters: {'n_estimators': 465, 'max_depth': 4, 'learning_rate': 0.061867247744275405, 'subsample': 0.9163198833504694, 'colsample_bytree': 0.9247409690954269, 'min_child_weight': 4, 'gamma': 4.004547429657753, 'reg_alpha': 0.3255086683253847, 'reg_lambda': 0.67798011694249}. Best is trial 3 with value: 0.9230744027027956.\n",
            "[I 2025-07-08 16:25:08,427] Trial 4 finished with value: 0.9134045481751562 and parameters: {'n_estimators': 885, 'max_depth': 10, 'learning_rate': 0.048067467841192035, 'subsample': 0.989954637942764, 'colsample_bytree': 0.9517704083227966, 'min_child_weight': 5, 'gamma': 2.4283634111915826, 'reg_alpha': 0.6558764274364056, 'reg_lambda': 0.12917651564164623}. Best is trial 3 with value: 0.9230744027027956.\n",
            "[I 2025-07-08 16:25:09,696] Trial 5 finished with value: 0.9214379885030629 and parameters: {'n_estimators': 538, 'max_depth': 6, 'learning_rate': 0.041154359995562634, 'subsample': 0.8317232321687628, 'colsample_bytree': 0.7409369387360576, 'min_child_weight': 2, 'gamma': 2.6468218021824446, 'reg_alpha': 0.07162757162649191, 'reg_lambda': 0.4900152415261837}. Best is trial 3 with value: 0.9230744027027956.\n",
            "[I 2025-07-08 16:25:14,468] Trial 6 finished with value: 0.9136038153764623 and parameters: {'n_estimators': 995, 'max_depth': 8, 'learning_rate': 0.07186311955524599, 'subsample': 0.8868456827081865, 'colsample_bytree': 0.7357652106704846, 'min_child_weight': 1, 'gamma': 1.095741061367253, 'reg_alpha': 0.07433418507722056, 'reg_lambda': 0.4032574376094673}. Best is trial 3 with value: 0.9230744027027956.\n",
            "[I 2025-07-08 16:25:15,535] Trial 7 finished with value: 0.9231587007706354 and parameters: {'n_estimators': 618, 'max_depth': 5, 'learning_rate': 0.03350205898790783, 'subsample': 0.822011278204632, 'colsample_bytree': 0.722166535224612, 'min_child_weight': 6, 'gamma': 0.24715219227684937, 'reg_alpha': 0.07524958562639716, 'reg_lambda': 0.9669566034834193}. Best is trial 7 with value: 0.9231587007706354.\n",
            "[I 2025-07-08 16:25:23,742] Trial 8 finished with value: 0.9208326417786526 and parameters: {'n_estimators': 893, 'max_depth': 10, 'learning_rate': 0.01163380961067282, 'subsample': 0.8984764092103804, 'colsample_bytree': 0.7722667880928702, 'min_child_weight': 5, 'gamma': 4.6798519160450285, 'reg_alpha': 0.5122794876765172, 'reg_lambda': 0.8135781035067061}. Best is trial 7 with value: 0.9231587007706354.\n",
            "[I 2025-07-08 16:25:25,271] Trial 9 finished with value: 0.915874199096136 and parameters: {'n_estimators': 871, 'max_depth': 5, 'learning_rate': 0.09209149739852704, 'subsample': 0.706448635612782, 'colsample_bytree': 0.7623209925432591, 'min_child_weight': 4, 'gamma': 1.9651314301580984, 'reg_alpha': 0.33821966411104576, 'reg_lambda': 0.47840595275538667}. Best is trial 7 with value: 0.9231587007706354.\n",
            "[I 2025-07-08 16:25:26,122] Trial 10 finished with value: 0.9239114057964984 and parameters: {'n_estimators': 697, 'max_depth': 3, 'learning_rate': 0.019170900424303507, 'subsample': 0.7658188258695521, 'colsample_bytree': 0.9115194526868834, 'min_child_weight': 8, 'gamma': 0.07470553798814347, 'reg_alpha': 0.9352280246724369, 'reg_lambda': 0.14175129323994928}. Best is trial 10 with value: 0.9239114057964984.\n",
            "[I 2025-07-08 16:25:26,909] Trial 11 finished with value: 0.923885852729281 and parameters: {'n_estimators': 703, 'max_depth': 3, 'learning_rate': 0.019206175446053932, 'subsample': 0.7743130104362936, 'colsample_bytree': 0.9007445812923655, 'min_child_weight': 8, 'gamma': 0.08835750810728432, 'reg_alpha': 0.9757520810403667, 'reg_lambda': 0.058977499175193446}. Best is trial 10 with value: 0.9239114057964984.\n",
            "[I 2025-07-08 16:25:27,792] Trial 12 finished with value: 0.9238182475515199 and parameters: {'n_estimators': 754, 'max_depth': 3, 'learning_rate': 0.011237019269226585, 'subsample': 0.7540626054096892, 'colsample_bytree': 0.9024669856817871, 'min_child_weight': 9, 'gamma': 0.9818568215035683, 'reg_alpha': 0.9829541779503426, 'reg_lambda': 0.012519642979372803}. Best is trial 10 with value: 0.9239114057964984.\n",
            "[I 2025-07-08 16:25:28,535] Trial 13 finished with value: 0.9240914616184741 and parameters: {'n_estimators': 728, 'max_depth': 3, 'learning_rate': 0.022258313174432075, 'subsample': 0.7752242003949182, 'colsample_bytree': 0.9798617371507534, 'min_child_weight': 9, 'gamma': 0.9590115024590378, 'reg_alpha': 0.8000423806969061, 'reg_lambda': 0.23666910014275178}. Best is trial 13 with value: 0.9240914616184741.\n",
            "[I 2025-07-08 16:25:29,641] Trial 14 finished with value: 0.9244511925903807 and parameters: {'n_estimators': 760, 'max_depth': 4, 'learning_rate': 0.026175945717673694, 'subsample': 0.7717056748493089, 'colsample_bytree': 0.997085161977759, 'min_child_weight': 10, 'gamma': 1.2033866259410977, 'reg_alpha': 0.7660792067582272, 'reg_lambda': 0.25040839730339604}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:30,631] Trial 15 finished with value: 0.9242175398363429 and parameters: {'n_estimators': 795, 'max_depth': 4, 'learning_rate': 0.029796830602823145, 'subsample': 0.7018847197806675, 'colsample_bytree': 0.9871299826408714, 'min_child_weight': 10, 'gamma': 1.3131878569205209, 'reg_alpha': 0.7607268252648043, 'reg_lambda': 0.2976554565780798}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:31,320] Trial 16 finished with value: 0.9239176139915813 and parameters: {'n_estimators': 303, 'max_depth': 5, 'learning_rate': 0.05846933979184328, 'subsample': 0.7019765534236104, 'colsample_bytree': 0.9999684438216013, 'min_child_weight': 10, 'gamma': 1.4939640360765385, 'reg_alpha': 0.7064390109974175, 'reg_lambda': 0.3177700781758689}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:35,391] Trial 17 finished with value: 0.9241987857712021 and parameters: {'n_estimators': 795, 'max_depth': 4, 'learning_rate': 0.029812831434156386, 'subsample': 0.7381170170690158, 'colsample_bytree': 0.9609624092007444, 'min_child_weight': 7, 'gamma': 3.1928846823169685, 'reg_alpha': 0.6381169169577493, 'reg_lambda': 0.2971365700072716}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:37,461] Trial 18 finished with value: 0.9202177141599763 and parameters: {'n_estimators': 998, 'max_depth': 6, 'learning_rate': 0.03893195977099352, 'subsample': 0.7975578066712893, 'colsample_bytree': 0.8695460940724162, 'min_child_weight': 10, 'gamma': 1.5198092238356657, 'reg_alpha': 0.7777443501148819, 'reg_lambda': 0.19158968185193395}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:39,212] Trial 19 finished with value: 0.9183865866958008 and parameters: {'n_estimators': 568, 'max_depth': 7, 'learning_rate': 0.052417324028221475, 'subsample': 0.7388215698192366, 'colsample_bytree': 0.9434013144335401, 'min_child_weight': 10, 'gamma': 3.1538084072237016, 'reg_alpha': 0.5651535459487658, 'reg_lambda': 0.3471744566714585}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:40,374] Trial 20 finished with value: 0.9244279278910935 and parameters: {'n_estimators': 797, 'max_depth': 4, 'learning_rate': 0.03079275625830407, 'subsample': 0.7262760726137552, 'colsample_bytree': 0.9976081724187298, 'min_child_weight': 7, 'gamma': 0.6897090536090392, 'reg_alpha': 0.7883391153289852, 'reg_lambda': 0.5911936162599473}. Best is trial 14 with value: 0.9244511925903807.\n",
            "[I 2025-07-08 16:25:41,540] Trial 21 finished with value: 0.9245887945785726 and parameters: {'n_estimators': 792, 'max_depth': 4, 'learning_rate': 0.0277302589951526, 'subsample': 0.726788077702315, 'colsample_bytree': 0.9991279987807871, 'min_child_weight': 7, 'gamma': 0.6653520789392553, 'reg_alpha': 0.8155403529570646, 'reg_lambda': 0.5780532435157548}. Best is trial 21 with value: 0.9245887945785726.\n",
            "[I 2025-07-08 16:25:42,660] Trial 22 finished with value: 0.9249106741712254 and parameters: {'n_estimators': 797, 'max_depth': 4, 'learning_rate': 0.02145194653264333, 'subsample': 0.7301289227546288, 'colsample_bytree': 0.9691482774813518, 'min_child_weight': 7, 'gamma': 0.5676705163767988, 'reg_alpha': 0.8501639561377875, 'reg_lambda': 0.5276643869634963}. Best is trial 22 with value: 0.9249106741712254.\n",
            "[I 2025-07-08 16:25:44,309] Trial 23 finished with value: 0.9241309041982244 and parameters: {'n_estimators': 946, 'max_depth': 5, 'learning_rate': 0.020587308829236903, 'subsample': 0.8052729964362284, 'colsample_bytree': 0.9601281658707049, 'min_child_weight': 7, 'gamma': 0.6053976767240347, 'reg_alpha': 0.8693091103011179, 'reg_lambda': 0.5640633301811124}. Best is trial 22 with value: 0.9249106741712254.\n",
            "[I 2025-07-08 16:25:45,391] Trial 24 finished with value: 0.9246317869498809 and parameters: {'n_estimators': 687, 'max_depth': 4, 'learning_rate': 0.023651721182051673, 'subsample': 0.8514889913687829, 'colsample_bytree': 0.9785979551454076, 'min_child_weight': 6, 'gamma': 1.7389722142832427, 'reg_alpha': 0.8540124934120561, 'reg_lambda': 0.4193176802804476}. Best is trial 22 with value: 0.9249106741712254.\n",
            "[I 2025-07-08 16:25:50,059] Trial 25 finished with value: 0.9247902620068005 and parameters: {'n_estimators': 681, 'max_depth': 6, 'learning_rate': 0.011394925102496876, 'subsample': 0.8678985230080326, 'colsample_bytree': 0.9328796703585062, 'min_child_weight': 6, 'gamma': 1.8333139991244436, 'reg_alpha': 0.8751291185272164, 'reg_lambda': 0.39080181227740857}. Best is trial 22 with value: 0.9249106741712254.\n",
            "[I 2025-07-08 16:25:51,823] Trial 26 finished with value: 0.9247800098202692 and parameters: {'n_estimators': 690, 'max_depth': 6, 'learning_rate': 0.012274962120985933, 'subsample': 0.8567080986180803, 'colsample_bytree': 0.9313559985577, 'min_child_weight': 6, 'gamma': 1.8669228270595406, 'reg_alpha': 0.8875333221659449, 'reg_lambda': 0.4118197301191251}. Best is trial 22 with value: 0.9249106741712254.\n",
            "[I 2025-07-08 16:25:53,173] Trial 27 finished with value: 0.9249415476060948 and parameters: {'n_estimators': 569, 'max_depth': 6, 'learning_rate': 0.014625128988498014, 'subsample': 0.8686956722250686, 'colsample_bytree': 0.8764867689231065, 'min_child_weight': 6, 'gamma': 2.883596026333291, 'reg_alpha': 0.9132226637262194, 'reg_lambda': 0.42077628971483133}. Best is trial 27 with value: 0.9249415476060948.\n",
            "[I 2025-07-08 16:25:55,364] Trial 28 finished with value: 0.9231214836296174 and parameters: {'n_estimators': 548, 'max_depth': 8, 'learning_rate': 0.016327432628695147, 'subsample': 0.8716249347803658, 'colsample_bytree': 0.8754274764109077, 'min_child_weight': 5, 'gamma': 3.0997491270016218, 'reg_alpha': 0.9960286774053887, 'reg_lambda': 0.5088769852535039}. Best is trial 27 with value: 0.9249415476060948.\n",
            "[I 2025-07-08 16:25:57,282] Trial 29 finished with value: 0.9197185847864142 and parameters: {'n_estimators': 496, 'max_depth': 9, 'learning_rate': 0.03896576641190789, 'subsample': 0.9515295202211504, 'colsample_bytree': 0.8153949690781137, 'min_child_weight': 8, 'gamma': 3.9262197391295377, 'reg_alpha': 0.7096241926916057, 'reg_lambda': 0.6899751501792608}. Best is trial 27 with value: 0.9249415476060948.\n",
            "[I 2025-07-08 16:25:59,262] Trial 30 finished with value: 0.9225255749484128 and parameters: {'n_estimators': 620, 'max_depth': 7, 'learning_rate': 0.015591503401837745, 'subsample': 0.9312012231040931, 'colsample_bytree': 0.816493259433966, 'min_child_weight': 4, 'gamma': 2.4357846592438683, 'reg_alpha': 0.9216528613191887, 'reg_lambda': 0.973853693175417}. Best is trial 27 with value: 0.9249415476060948.\n",
            "[I 2025-07-08 16:26:04,062] Trial 31 finished with value: 0.9249139249139535 and parameters: {'n_estimators': 651, 'max_depth': 6, 'learning_rate': 0.010232927556417819, 'subsample': 0.8664011447951135, 'colsample_bytree': 0.9300173628325522, 'min_child_weight': 6, 'gamma': 2.75126854847803, 'reg_alpha': 0.9136366152635331, 'reg_lambda': 0.39996307937198183}. Best is trial 27 with value: 0.9249415476060948.\n",
            "[I 2025-07-08 16:26:05,460] Trial 32 finished with value: 0.9251999025936961 and parameters: {'n_estimators': 603, 'max_depth': 6, 'learning_rate': 0.014978262369296492, 'subsample': 0.8740863783426523, 'colsample_bytree': 0.8783989523011685, 'min_child_weight': 6, 'gamma': 2.8172083185817187, 'reg_alpha': 0.9179637631148176, 'reg_lambda': 0.3730845668262447}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:06,887] Trial 33 finished with value: 0.924522290622737 and parameters: {'n_estimators': 456, 'max_depth': 7, 'learning_rate': 0.018437059984470254, 'subsample': 0.8322046534892854, 'colsample_bytree': 0.8393510696649639, 'min_child_weight': 5, 'gamma': 2.840380637766512, 'reg_alpha': 0.9231870421785866, 'reg_lambda': 0.5225129715106656}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:08,198] Trial 34 finished with value: 0.9206828129579079 and parameters: {'n_estimators': 580, 'max_depth': 6, 'learning_rate': 0.06779824495875683, 'subsample': 0.8856276964726868, 'colsample_bytree': 0.8765978274581263, 'min_child_weight': 7, 'gamma': 3.6582117429798, 'reg_alpha': 0.20279790341234571, 'reg_lambda': 0.43766653576090386}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:09,168] Trial 35 finished with value: 0.9223321838970883 and parameters: {'n_estimators': 502, 'max_depth': 5, 'learning_rate': 0.0356151485625205, 'subsample': 0.9150452967944868, 'colsample_bytree': 0.891793218906054, 'min_child_weight': 3, 'gamma': 3.4900866116245, 'reg_alpha': 0.6985035568442707, 'reg_lambda': 0.6424515565998835}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:11,931] Trial 36 finished with value: 0.9201672028662782 and parameters: {'n_estimators': 644, 'max_depth': 9, 'learning_rate': 0.024028573406682047, 'subsample': 0.9351266707244215, 'colsample_bytree': 0.8555378035762522, 'min_child_weight': 6, 'gamma': 2.81231687912351, 'reg_alpha': 0.6119710780959022, 'reg_lambda': 0.3463986626102384}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:13,732] Trial 37 finished with value: 0.9218565535975823 and parameters: {'n_estimators': 443, 'max_depth': 7, 'learning_rate': 0.04788079395009252, 'subsample': 0.8347573846852284, 'colsample_bytree': 0.920132500896075, 'min_child_weight': 5, 'gamma': 2.253008420637549, 'reg_alpha': 0.8270177505672599, 'reg_lambda': 0.7372961457681018}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:18,701] Trial 38 finished with value: 0.9236392593830738 and parameters: {'n_estimators': 601, 'max_depth': 6, 'learning_rate': 0.015245877722337944, 'subsample': 0.802785339637838, 'colsample_bytree': 0.7974790015576251, 'min_child_weight': 3, 'gamma': 3.530465782841838, 'reg_alpha': 0.9645896394225706, 'reg_lambda': 0.4882918007096871}. Best is trial 32 with value: 0.9251999025936961.\n",
            "[I 2025-07-08 16:26:20,508] Trial 39 finished with value: 0.924420921030154 and parameters: {'n_estimators': 417, 'max_depth': 8, 'learning_rate': 0.010440405974319222, 'subsample': 0.8837854276168241, 'colsample_bytree': 0.8853031349997429, 'min_child_weight': 8, 'gamma': 4.576891000515234, 'reg_alpha': 0.3867667378264578, 'reg_lambda': 0.61140211990861}. Best is trial 32 with value: 0.9251999025936961.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'n_estimators': 603, 'max_depth': 6, 'learning_rate': 0.014978262369296492, 'subsample': 0.8740863783426523, 'colsample_bytree': 0.8783989523011685, 'min_child_weight': 6, 'gamma': 2.8172083185817187, 'reg_alpha': 0.9179637631148176, 'reg_lambda': 0.3730845668262447}\n",
            "Best Validation R² Score: 0.9251999025936961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# Outlier removal\n",
        "z_scores = (X - X.mean()) / X.std()\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Bagging with noise\n",
        "n_models = 5\n",
        "val_preds_list = []\n",
        "test_preds_list = []\n",
        "\n",
        "for seed in range(n_models):\n",
        "    noise = np.random.normal(0, 0.01, X_train.shape)\n",
        "    X_train_noisy = X_train + noise\n",
        "\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=6,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.9,\n",
        "        random_state=seed,\n",
        "        verbosity=0\n",
        "    )\n",
        "    model.fit(X_train_noisy, y_train)\n",
        "    val_preds_list.append(model.predict(X_val))\n",
        "    test_preds_list.append(model.predict(X_test_scaled))\n",
        "\n",
        "# Average predictions\n",
        "val_preds_avg = np.mean(val_preds_list, axis=0)\n",
        "test_preds_avg = np.mean(test_preds_list, axis=0)\n",
        "\n",
        "# Score\n",
        "r2 = r2_score(y_val, val_preds_avg)\n",
        "print(f\"R² Score: {r2:.5f}\")\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'id': test_df['id'], 'output': test_preds_avg})\n",
        "submission.to_csv(\"submission_xgb_bagged.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2w1mB5M3xuE",
        "outputId": "1d3202ee-5090-4b28-b726-3fc70f4ab567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.92424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Ridge Regression**"
      ],
      "metadata": {
        "id": "YrnQtPAwG0aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Ridge Regression model\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Validation performance\n",
        "val_preds = ridge_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test data\n",
        "test_preds = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_ridge_regression.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeEP5bLG4f-T",
        "outputId": "7c2c11ae-69ee-49ba-f89d-bb4febf9c2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation: 0.90824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Ridge Regression with PCA and Polynomial Feature**"
      ],
      "metadata": {
        "id": "rcxgryEIG4KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Polynomial Features (degree=2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# ✅ Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_poly_scaled = scaler.fit_transform(X_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# ✅ PCA for Dimensionality Reduction\n",
        "pca = PCA(n_components=0.95)  # retain 95% variance\n",
        "X_pca = pca.fit_transform(X_poly_scaled)\n",
        "X_test_pca = pca.transform(X_test_poly_scaled)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# ✅ Ridge Regression Model\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Validation performance\n",
        "val_preds = ridge_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = ridge_model.predict(X_test_pca)\n",
        "\n",
        "# ✅ Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_ridge_poly_pca.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GalsSSHH48Sv",
        "outputId": "bf89f8ba-7bb0-4330-abde-8dafc21f02f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation: 0.88904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net Regressor with polynomia feature and PCA**"
      ],
      "metadata": {
        "id": "hqDA_Nv1HCMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Polynomial Features (degree=2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# ✅ Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_poly_scaled = scaler.fit_transform(X_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# ✅ PCA (retain 95% variance)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_poly_scaled)\n",
        "X_test_pca = pca.transform(X_test_poly_scaled)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_pca, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Elastic Net Model\n",
        "elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000, random_state=42)\n",
        "elastic_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Validation performance\n",
        "val_preds = elastic_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = elastic_model.predict(X_test_pca)\n",
        "\n",
        "# ✅ Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_elasticnet_poly_pca.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWODW-yT5KJO",
        "outputId": "9e2dc304-50b5-44ad-e5bb-7276a3fdeef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation: 0.88802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net Regressor**"
      ],
      "metadata": {
        "id": "JPMaaYEJHJI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Elastic Net Regression\n",
        "elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000, random_state=42)\n",
        "elastic_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ R² Score on validation\n",
        "val_preds = elastic_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"✅ R² Score on validation: {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = elastic_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_elasticnet.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYRbfJYu5VVg",
        "outputId": "3bfab8c3-05c1-4f6e-c39e-ba59fdd15d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ R² Score on validation: 0.87229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Decision Tree with Outlier Removal**"
      ],
      "metadata": {
        "id": "2ZfoS08YHOh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare data\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal using Z-score\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Decision Tree Regressor\n",
        "dt_model = DecisionTreeRegressor(max_depth=6, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Validation prediction and R² score\n",
        "val_preds = dt_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"🌳 Decision Tree R² Score: {r2:.5f}\")\n",
        "\n",
        "# ✅ Test set prediction\n",
        "test_preds = dt_model.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_decision_tree_outlier.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJnYtEfv6iO4",
        "outputId": "3fb970f3-debf-4129-d3d4-65dec7b154bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌳 Decision Tree R² Score: 0.90371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features & target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Z-score based outlier removal\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Polynomial features (degree=2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_poly_scaled = scaler.fit_transform(X_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# ✅ PCA (retain 95% variance)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_poly_scaled)\n",
        "X_test_pca = pca.transform(X_test_poly_scaled)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_pca, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ LGBM Regressor\n",
        "lgbm_model = LGBMRegressor(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42\n",
        ")\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate on validation set\n",
        "val_preds = lgbm_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"📦 LGBM R² Score: {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = lgbm_model.predict(X_test_pca)\n",
        "\n",
        "# ✅ Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_lgbm_poly_pca.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrZhypFv6xDH",
        "outputId": "4804d9af-cc98-443a-d849-29b860c1c63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 7576, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 6013.503117\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 LGBM R² Score: 0.89149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Z-score based outlier removal\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Polynomial feature expansion (degree=2)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_poly_scaled = scaler.fit_transform(X_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_poly_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ LGBM Regressor\n",
        "lgbm_model = LGBMRegressor(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42\n",
        ")\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ R² score on validation set\n",
        "val_preds = lgbm_model.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"📦 LGBM R² Score (no PCA): {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test data\n",
        "test_preds = lgbm_model.predict(X_test_poly_scaled)\n",
        "\n",
        "# ✅ Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_lgbm_poly_nopca.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Md3mCV6--E",
        "outputId": "f5a9247e-b3f8-48b9-ba6c-07df28bf8885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032131 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 13400\n",
            "[LightGBM] [Info] Number of data points in the train set: 7576, number of used features: 152\n",
            "[LightGBM] [Info] Start training from score 6013.503117\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 LGBM R² Score (no PCA): 0.91902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Z-score based outlier removal\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Hyperparameter tuning for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 300],\n",
        "    'max_depth': [10, 15, 25],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# ✅ R² score on validation set\n",
        "val_preds = best_rf.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(f\"🌲 Best Random Forest R² Score: {r2:.5f}\")\n",
        "print(\"🔧 Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_random_forest_hypertuned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed8Vn_Il7aUy",
        "outputId": "9557675d-c31a-4589-e9b6-51dacb089f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "🌲 Best Random Forest R² Score: 0.92086\n",
            "🔧 Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = train_df.drop(columns=['output', 'Row#'])\n",
        "y = train_df['output']\n",
        "X_test = test_df.drop(columns=['id', 'Row#'])\n",
        "\n",
        "# ✅ Outlier removal\n",
        "z_scores = zscore(X)\n",
        "mask = (np.abs(z_scores) < 3).all(axis=1)\n",
        "X, y = X[mask], y[mask]\n",
        "\n",
        "# ✅ Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'max_depth': [10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 3],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# ✅ Validation performance\n",
        "val_preds = best_rf.predict(X_val)\n",
        "r2 = r2_score(y_val, val_preds)\n",
        "print(\"✅ Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"🌲 Random Forest R² Score (validation): {r2:.5f}\")\n",
        "\n",
        "# ✅ Predict on test set\n",
        "test_preds = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Save submission file\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'output': test_preds\n",
        "})\n",
        "submission.to_csv(\"submission_rf_hypertuned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0SSNJk682jK",
        "outputId": "08cf8c70-1a48-4b9d-a814-1b1f6a39cf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "✅ Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "🌲 Random Forest R² Score (validation): 0.92086\n"
          ]
        }
      ]
    }
  ]
}